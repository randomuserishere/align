device: "cuda"
train_seed: 1
model_name: "google/gemma-2b-it"
tokenizer_name: "google/gemma-2b-it"
data_name: "OpenAssistant/oasst1"
peft_config:
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
  lora_dropout: 0.5
  alpha: 16
  r: 16
dpo:
  learning_rate: 5.0e-5
  batch_size: 2
  grad_accum: 4
  warmup_steps: 50
  epochs: 1
  scheduler: "cosine"
  optim: "paged_adamw_32bit"
  max_seq_length: 1024
  max_prompt_length: 1024
output_dir: "."
sft:
  learning_rate: 5.0e-5
  batch_size: 2
  grad_accum: 4
  warmup_steps: 30
  weight_decay: 0.001
  epochs: 1
  scheduler: "cosine"
  optim: "paged_adamw_32bit"
  max_seq_length: 1024
iteration: 3
new_prompts_num: 500
num_responses: 4
proportion: 0.7